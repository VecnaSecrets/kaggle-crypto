{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SeparatePredictor import SeparatePredictor\n",
    "from train_tools import LSTMRegressor\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from flaml import AutoML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING fcoin_1\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.66; Val Loss: 6.09: 100%|██████████| 4500/4500 [01:36<00:00, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total r2 score 0.02825482486012776\n",
      "Total mse score 6.408326148986816\n",
      "TRAINING fcoin_2\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.64; Val Loss: 2.50: 100%|██████████| 4500/4500 [01:44<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total r2 score -0.030839449482138903\n",
      "Total mse score 2.2637577056884766\n",
      "TRAINING fcoin_3\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.60; Val Loss: 4.60: 100%|██████████| 4500/4500 [01:36<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total r2 score -0.05088303594706489\n",
      "Total mse score 4.698777675628662\n",
      "TRAINING fcoin_4\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.27; Val Loss: 4.45: 100%|██████████| 4500/4500 [01:37<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total r2 score -0.13625975815084534\n",
      "Total mse score 4.6782684326171875\n",
      "TRAINING fcoin_5\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.42; Val Loss: 2.68: 100%|██████████| 4500/4500 [01:36<00:00, 46.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total r2 score -0.06372646147231897\n",
      "Total mse score 2.7348034381866455\n",
      "TRAINING fcoin_6\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.64; Val Loss: 2.82:  12%|█▏        | 519/4500 [00:11<01:27, 45.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m predictor \u001B[38;5;241m=\u001B[39m SeparatePredictor(models \u001B[38;5;241m=\u001B[39m [LSTMRegressor], params\u001B[38;5;241m=\u001B[39mparams, data\u001B[38;5;241m=\u001B[39mdf)\n\u001B[1;32m     12\u001B[0m predictor\u001B[38;5;241m.\u001B[39mprepare()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m                \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m preds \u001B[38;5;241m=\u001B[39m predictor\u001B[38;5;241m.\u001B[39mpredict(df_t, device\u001B[38;5;241m=\u001B[39mDEVICE)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_t\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/Desktop/Hacks/kaggle-crypto/SeparatePredictor.py:132\u001B[0m, in \u001B[0;36mSeparatePredictor.train\u001B[0;34m(self, device, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_labels:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTRAINING f\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 132\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_class\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_loader\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m     r2, mse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_f(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels[\u001B[38;5;28mcls\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_ds[\u001B[38;5;28mcls\u001B[39m], device)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal r2 score \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mr2\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/Hacks/kaggle-crypto/SeparatePredictor.py:171\u001B[0m, in \u001B[0;36mSeparatePredictor.train_class\u001B[0;34m(self, model, train_loader, test_loader, epochs, learning_rate, loss_fn, optimizer_cl, optimizer_params, device, writer, other_train_params)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    169\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m optimizer_cl(model\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptimizer_params)\n\u001B[0;32m--> 171\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43mwriter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_train_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Hacks/kaggle-crypto/train_tools.py:50\u001B[0m, in \u001B[0;36mTrainModel\u001B[0;34m(model, loss_fn, optimizer, train_loader, val_loader, epochs, display_on_epoch, device, writer)\u001B[0m\n\u001B[1;32m     47\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m     49\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 50\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m display_on_epoch \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "params = {\n",
    "    'input_size': 3,\n",
    "    'hidden_dim':64,\n",
    "    'n_layers': 2,\n",
    "    'device':DEVICE\n",
    "}\n",
    "df = pd.read_csv('train.csv')\n",
    "df_t = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = SeparatePredictor(models = [LSTMRegressor], params=params, data=df)\n",
    "predictor.prepare()\n",
    "predictor.train(device=DEVICE, epochs=4500,\n",
    "                learning_rate=1e-4)\n",
    "preds = predictor.predict(df_t, device=DEVICE)\n",
    "print(df_t.shape)\n",
    "print(preds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for n in predictor.models['coin_1'].parameters():\n",
    "    print(n.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = [LSTMRegressor]\n",
    "model = model[0](**params).to(device=DEVICE)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class Pipeline_autoML:\n",
    "    \"\"\"\n",
    "    Пайплайн для некого пандаса одной монеты уже с выброшенными лишними фичами.\n",
    "    \"\"\"\n",
    "    def __init__(self, impute_strategy='mean'):\n",
    "        self.imputer = SimpleImputer(strategy=impute_strategy)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def fit(self, X_raw: pd.DataFrame, y_raw: pd.Series = None):\n",
    "        self.imputer.fit(X_raw)\n",
    "        self.scaler.fit(X_raw)\n",
    "\n",
    "    def transform(self, X_raw: pd.DataFrame, y_raw=None):\n",
    "        res = self.imputer.transform(X_raw)\n",
    "        res = self.scaler.transform(res)\n",
    "\n",
    "        if y_raw is not None:\n",
    "            return res, y_raw\n",
    "        return res\n",
    "\n",
    "    def fit_transform(self, *args, **kwargs):\n",
    "        self.fit(*args)\n",
    "        return self.transform(*args, **kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "class AutoMLpred(SeparatePredictor):\n",
    "    def prepare(self):\n",
    "        self.devided_data, self.y_devided, self.class_labels = self.separate_data(self.raw_data, self.y)\n",
    "        self.models = dict(zip(self.class_labels, self.models))\n",
    "        self.set_up_pipeline()\n",
    "\n",
    "        self.train_test_split()\n",
    "\n",
    "        self.fit_preprocess()\n",
    "        self.X_train = self.prepare_data(self.X_train)\n",
    "        self.X_test = self.prepare_data(self.X_test)\n",
    "\n",
    "    def set_up_pipeline(self):\n",
    "            \"\"\"\n",
    "            here we will define our preprocess pipeline as well as training functions\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            self.preprocess_p = dict(zip(self.class_labels, [Pipeline_autoML() for _ in range(self.num_classes)]))\n",
    "            self.train_f = None\n",
    "            self.validate_f = None\n",
    "\n",
    "    def train(self, train_params={}):\n",
    "        for cls in self.class_labels:\n",
    "            print(f\"TRAINING f{cls}\")\n",
    "            self.models[cls].fit(self.X_train[cls], self.y_train[cls], **train_params)\n",
    "\n",
    "            preds = self.models[cls].predict(self.X_train[cls])\n",
    "            r2 = r2_score(self.y_train[cls], preds)\n",
    "            mse = mean_squared_error(self.y_train[cls], preds)\n",
    "\n",
    "            print(f\"Total train r2 score {r2}\")\n",
    "            print(f\"Total train mse score {mse}\")\n",
    "\n",
    "            preds = self.models[cls].predict(self.X_test[cls])\n",
    "            r2 = r2_score(self.y_test[cls], preds)\n",
    "            mse = mean_squared_error(self.y_test[cls], preds)\n",
    "\n",
    "            print(f\"Total test r2 score {r2}\")\n",
    "            print(f\"Total test mse score {mse}\")\n",
    "\n",
    "    def predict(self, X:pd.DataFrame):\n",
    "        res = pd.DataFrame(index=X.index, data=np.zeros(X.shape[0]))\n",
    "\n",
    "        X_separated, classes = self.separate_data(X)\n",
    "        X_ds = self.prepare_data(X_separated)\n",
    "        out = {}\n",
    "        for cls in classes:\n",
    "            out[cls] = self.models[cls].predict(X_ds[cls])\n",
    "            res.loc[X[self.feat_devide] == cls] = out[cls].reshape(-1,1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def evaluate(self):\n",
    "        preds = self.predict(self.X_test)\n",
    "        r2 = r2_score(self.df[self.target].values, preds)\n",
    "        mse = mean_squared_error(self.df[self.target].values, preds)\n",
    "\n",
    "        print(f\"Total r2 score {r2}\")\n",
    "        print(f\"Total mse score {mse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0', 'Id', 'date', 'coin_id', 'fwd_ret_3d', 'feat_1', 'feat_2',\n       'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7', 'feat_8', 'feat_9',\n       'feat_10'],\n      dtype='object')"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING fcoin_1\n",
      "Total train r2 score 0.8771032717042755\n",
      "Total train mse score 0.3608563388783512\n",
      "Total test r2 score 0.06225745126906734\n",
      "Total test mse score 6.184090429286921\n",
      "TRAINING fcoin_2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[92], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m auto_ml \u001B[38;5;241m=\u001B[39m AutoMLpred(models\u001B[38;5;241m=\u001B[39m[AutoML], data\u001B[38;5;241m=\u001B[39mdf_test, relevant_features\u001B[38;5;241m=\u001B[39mfeatures)\n\u001B[1;32m     13\u001B[0m auto_ml\u001B[38;5;241m.\u001B[39mprepare()\n\u001B[0;32m---> 14\u001B[0m \u001B[43mauto_ml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# automl = AutoML()\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# automl.fit(x_train, y_train, task=\"regression\", time_budget=600, metric = 'mse')\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# y_pred = automl.predict(x_test)\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[79], line 25\u001B[0m, in \u001B[0;36mAutoMLpred.train\u001B[0;34m(self, train_params)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_labels:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTRAINING f\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 25\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrain_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels[\u001B[38;5;28mcls\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train[\u001B[38;5;28mcls\u001B[39m])\n\u001B[1;32m     28\u001B[0m     r2 \u001B[38;5;241m=\u001B[39m r2_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_train[\u001B[38;5;28mcls\u001B[39m], preds)\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/automl.py:3021\u001B[0m, in \u001B[0;36mAutoML.fit\u001B[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, cv_score_agg_func, skip_transform, fit_kwargs_by_estimator, **fit_kwargs)\u001B[0m\n\u001B[1;32m   3019\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3020\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_training_log \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3021\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3022\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_best_estimator:\n\u001B[1;32m   3023\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit succeeded\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/automl.py:3610\u001B[0m, in \u001B[0;36mAutoML._search\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   3608\u001B[0m     state\u001B[38;5;241m.\u001B[39mbest_config \u001B[38;5;241m=\u001B[39m state\u001B[38;5;241m.\u001B[39minit_config[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m state\u001B[38;5;241m.\u001B[39minit_config \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m   3609\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_ray \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_spark \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m-> 3610\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_search_sequential\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3611\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3612\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_search_parallel()\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/automl.py:3432\u001B[0m, in \u001B[0;36mAutoML._search_sequential\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   3426\u001B[0m         search_state\u001B[38;5;241m.\u001B[39msearch_alg\u001B[38;5;241m.\u001B[39msearcher\u001B[38;5;241m.\u001B[39mset_search_properties(\n\u001B[1;32m   3427\u001B[0m             metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3428\u001B[0m             mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3429\u001B[0m             metric_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state\u001B[38;5;241m.\u001B[39mbest_loss,\n\u001B[1;32m   3430\u001B[0m         )\n\u001B[1;32m   3431\u001B[0m start_run_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m-> 3432\u001B[0m analysis \u001B[38;5;241m=\u001B[39m \u001B[43mtune\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3433\u001B[0m \u001B[43m    \u001B[49m\u001B[43msearch_state\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3434\u001B[0m \u001B[43m    \u001B[49m\u001B[43msearch_alg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msearch_state\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_alg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_budget_s\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_budget_s\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3437\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_ray\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3438\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_spark\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3439\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3440\u001B[0m time_used \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_run_time\n\u001B[1;32m   3441\u001B[0m better \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/tune/tune.py:782\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, **ray_args)\u001B[0m\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[1;32m    781\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrial \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_trials\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m config: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrial_to_run\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 782\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mevaluation_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial_to_run\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/automl.py:386\u001B[0m, in \u001B[0;36mAutoMLState._compute_with_config_base\u001B[0;34m(config_w_resource, state, estimator, is_report)\u001B[0m\n\u001B[1;32m    368\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFLAML_sample_size\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    369\u001B[0m budget \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    370\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    371\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m state\u001B[38;5;241m.\u001B[39mtime_budget \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;241m/\u001B[39m state\u001B[38;5;241m.\u001B[39mdata_size[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    378\u001B[0m )\n\u001B[1;32m    380\u001B[0m (\n\u001B[1;32m    381\u001B[0m     trained_estimator,\n\u001B[1;32m    382\u001B[0m     val_loss,\n\u001B[1;32m    383\u001B[0m     metric_for_logging,\n\u001B[1;32m    384\u001B[0m     _,\n\u001B[1;32m    385\u001B[0m     pred_time,\n\u001B[0;32m--> 386\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_estimator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43msampled_X_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43msampled_y_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_time_limit\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbudget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbudget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_time_limit\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_method\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearner_classes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcv_score_agg_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_training_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthis_estimator_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state\u001B[38;5;241m.\u001B[39mretrain_final \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m state\u001B[38;5;241m.\u001B[39mmodel_history:\n\u001B[1;32m    411\u001B[0m     trained_estimator\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/ml.py:645\u001B[0m, in \u001B[0;36mcompute_estimator\u001B[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001B[0m\n\u001B[1;32m    625\u001B[0m     val_loss, metric_for_logging, train_time, pred_time \u001B[38;5;241m=\u001B[39m get_val_loss(\n\u001B[1;32m    626\u001B[0m         config_dic,\n\u001B[1;32m    627\u001B[0m         estimator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    642\u001B[0m         free_mem_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m    643\u001B[0m     )\n\u001B[1;32m    644\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 645\u001B[0m     val_loss, metric_for_logging, train_time, pred_time \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model_CV\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    646\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_dic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbudget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    654\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbest_val_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    655\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcv_score_agg_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    656\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_training_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_training_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    657\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    658\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    661\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, TransformersEstimator):\n\u001B[1;32m    662\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m], fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_val\u001B[39m\u001B[38;5;124m\"\u001B[39m], fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_val\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/ml.py:555\u001B[0m, in \u001B[0;36mevaluate_model_CV\u001B[0;34m(config, estimator, X_train_all, y_train_all, budget, kf, task, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    554\u001B[0m     groups_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 555\u001B[0m val_loss_i, metric_i, train_time_i, pred_time_i \u001B[38;5;241m=\u001B[39m \u001B[43mget_val_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbudget_per_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_training_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_training_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(metric_i, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mintermediate_results\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m metric_i\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m metric_i[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mintermediate_results\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/ml.py:443\u001B[0m, in \u001B[0;36mget_val_loss\u001B[0;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, obj, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001B[0m\n\u001B[1;32m    438\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    439\u001B[0m \u001B[38;5;66;03m# if groups_val is not None:\u001B[39;00m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;66;03m#     fit_kwargs['groups_val'] = groups_val\u001B[39;00m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;66;03m#     fit_kwargs['X_val'] = X_val\u001B[39;00m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;66;03m#     fit_kwargs['y_val'] = y_val\u001B[39;00m\n\u001B[0;32m--> 443\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbudget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    444\u001B[0m val_loss, metric_for_logging, pred_time, _ \u001B[38;5;241m=\u001B[39m _eval_estimator(\n\u001B[1;32m    445\u001B[0m     config,\n\u001B[1;32m    446\u001B[0m     estimator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    457\u001B[0m     fit_kwargs,\n\u001B[1;32m    458\u001B[0m )\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mintermediate_results\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/model.py:1388\u001B[0m, in \u001B[0;36mXGBoostSklearnEstimator.fit\u001B[0;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001B[0m\n\u001B[1;32m   1386\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtree_method\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu_hist\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1387\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu_per_trial\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1388\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbudget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfree_mem_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/model.py:1147\u001B[0m, in \u001B[0;36mLGBMEstimator.fit\u001B[0;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[1;32m   1146\u001B[0m         callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1147\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1154\u001B[0m     \u001B[38;5;66;03m# for xgboost>=1.6.0, pop callbacks to enable pickle\u001B[39;00m\n\u001B[1;32m   1155\u001B[0m     callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/flaml/automl/model.py:197\u001B[0m, in \u001B[0;36mBaseEstimator._fit\u001B[0;34m(self, X_train, y_train, **kwargs)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logger\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m==\u001B[39m logging\u001B[38;5;241m.\u001B[39mDEBUG:\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# xgboost 1.6 doesn't display all the params in the model str\u001B[39;00m\n\u001B[1;32m    196\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflaml.model - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fit started with params \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 197\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logger\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m==\u001B[39m logging\u001B[38;5;241m.\u001B[39mDEBUG:\n\u001B[1;32m    199\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflaml.model - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fit finished\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1014\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1016\u001B[0m (\n\u001B[1;32m   1017\u001B[0m     model,\n\u001B[1;32m   1018\u001B[0m     metric,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1023\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[1;32m   1024\u001B[0m )\n\u001B[0;32m-> 1025\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1033\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1034\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1035\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1037\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/xgboost/training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Stonks/lib/python3.10/site-packages/xgboost/core.py:1918\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dmatrix_features(dtrain)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1918\u001B[0m     _check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1919\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1922\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'task': \"regression\",\n",
    "    'time_budget': 600,\n",
    "    'metric': 'mse',\n",
    "    'verbose': 0,\n",
    "}\n",
    "features = ['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_8', 'feat_9', 'feat_10']\n",
    "coins = ['coin_1', 'coin_2', 'coin_3', 'coin_4']\n",
    "df_test = df.loc[df['coin_id'].isin(coins)]\n",
    "\n",
    "\n",
    "auto_ml = AutoMLpred(models=[AutoML], data=df_test, relevant_features=features)\n",
    "auto_ml.prepare()\n",
    "auto_ml.train(train_params)\n",
    "\n",
    "# automl = AutoML()\n",
    "# automl.fit(x_train, y_train, task=\"regression\", time_budget=600, metric = 'mse')\n",
    "# y_pred = automl.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "              0\n0     -0.155895\n1     -0.198345\n2     -2.101173\n3      2.303399\n4      0.553546\n...         ...\n36720  0.085418\n36721 -0.111529\n36722  0.007720\n36723 -0.437889\n36724  0.029095\n\n[36725 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.155895</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.198345</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2.101173</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.303399</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.553546</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36720</th>\n      <td>0.085418</td>\n    </tr>\n    <tr>\n      <th>36721</th>\n      <td>-0.111529</td>\n    </tr>\n    <tr>\n      <th>36722</th>\n      <td>0.007720</td>\n    </tr>\n    <tr>\n      <th>36723</th>\n      <td>-0.437889</td>\n    </tr>\n    <tr>\n      <th>36724</th>\n      <td>0.029095</td>\n    </tr>\n  </tbody>\n</table>\n<p>36725 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = auto_ml.predict(df)\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.23205342813902097\n",
      "3.6489872056279213\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(df['fwd_ret_3d'][32000:].values, preds[32000:])\n",
    "mse = mean_squared_error(df['fwd_ret_3d'][32000:].values, preds[32000:])\n",
    "\n",
    "print(r2)\n",
    "print(mse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# preds = auto_ml.predict(df_t)\n",
    "preds[\"Id\"]=df_t['Id']\n",
    "preds.index = df_t['Id']\n",
    "preds[\"Predicted\"] = preds[0]\n",
    "preds.drop(0,axis=1)\n",
    "preds.to_csv('./submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "preds.to_csv('./submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
